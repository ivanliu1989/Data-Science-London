setwd("/Users/ivan/Work_directory/Data-Science-London")
library(caret)
x <- read.csv("Data/train.csv", header = F)
test <- read.csv("Data/test.csv", header = F)
y <- read.csv("Data/trainLabels.csv", header= F)
names(y)<- 'result'
x <- cbind(x,y)
x$result <- as.factor(x$result)
levels(x$result) <- c('No','Yes')
mean(is.na(x))
index <- createDataPartition(x$result, p = 0.8,list = F)
x_train <- x[index,]
x_test <- x[-index,]
x_train_1 <- x_train[,-41]
prep <- preProcess(x = x_train_1, method=c('center','scale'))
x_train_1 <- predict(prep, x_train_1)
x_train_1 <- cbind(x_train_1, x_train[,41])
Grid <- expand.grid(C=seq(1,10,0.5))
fitControl <- trainControl(method="repeatedcv",10,10,classProbs = T)
fit_svmRadialCost <- train(result~V15+V13+V19+V35+V29+V40+V37+V33+V7+V24+V12+V5+V2+V21,
method='svmRadialCost', data=x_train,
trControl = fitControl, verbose=T, preProcess=c('pca','center','scale'),
tuneGrid=Grid)
Pred <- predict(fit_svmRadialCost, x_train_1)
confusionMatrix(Pred, x_train_1[,41])
Pred <- predict(fit_svmRadialCost, x_train_1)
Pred <- predict(fit_svmRadialCost, x_train)
Pred <- predict(fit_svmRadialCost, x_train)
rm(list=ls())
x <- read.csv("Data/train.csv", header = F)
test <- read.csv("Data/test.csv", header = F)
y <- read.csv("Data/trainLabels.csv", header= F)
names(y)<- 'result'
x <- cbind(x,y)
str(x)
x$result <- as.factor(x$result)
levels(x$result) <- c('No','Yes')
mean(is.na(x))
index <- createDataPartition(x$result, p = 0.8,list = F)
x_train <- x[index,]
x_test <- x[-index,]
qqnorm(x_train[,1])
plot(x_train[,1], type='density')
plot(density(x_train[,1]))
qqnorm(x_train[,1])
fit_gaussprLinear <- train(result~., method='gaussprLinear', data=x_train,
verbose=T, preProcess=c('pca','center','scale'))
fit_gaussprLinear
Pred <- predict(fit_svmRadialCost, x_train)
Pred <- predict(fit_gaussprLinear, x_train)
confusionMatrix(Pred, x_train_1[,41])
confusionMatrix(Pred, x_train[,41])
featureSelection <- varImp(fit_gaussprLinear)
plot(featureSelection)
featureSelection
Pred_gaussprLinear <- predict(fit_gaussprLinear, x_train)
confusionMatrix(Pred_gaussprLinear, x_train[,41])
x_train_gmm <- cbind(x_train, Pred_gaussprLinear)
head(x_train_gmm)
Grid <- expand.grid(C=seq(1,10,0.5))
fitControl <- trainControl(method="repeatedcv",10,10,classProbs = T)
fit_svmRadialCost <- train(result~V15+V13+V19+V35+V29+V40+V37+V33+V7+V24+V12+V5+V2+V21+Pred_gaussprLinear,
method='svmRadialCost', data=x_train_gmm,
trControl = fitControl, verbose=T, preProcess=c('pca','center','scale'),
tuneGrid=Grid)
Pred <- predict(fit_svmRadialCost, x_train_gmm)
confusionMatrix(Pred, x_train_gmm[,41])
Pred_gaussprLinear_test <- predict(fit_gaussprLinear, x_test)
x_test_gmm <- cbind(x_test, Pred_gaussprLinear_test)
Pred <- predict(fit_svmRadialCost, x_test_gmm)
Pred_test <- predict(fit_svmRadialCost, x_test_gmm)
str(x_test)
str(Pred_gaussprLinear_test)
Pred_test <- predict(fit_svmRadialCost, x_test_gmm)
Pred_gaussprLinear <- predict(fit_gaussprLinear, x_test)
x_test_gmm <- cbind(x_test, Pred_gaussprLinear_test)
Pred_test <- predict(fit_svmRadialCost, x_test_gmm)
confusionMatrix(Pred, x_test$result) ## acc 0.88 after 1st feature selection
confusionMatrix(Pred_test, x_test_gmm$result) ## acc 0.88 after 1st feature selection
featureSelection <- varImp(fit_svmRadialCost)
plot(featureSelection)
setwd("/Users/ivan/Work_directory/Data-Science-London")
library(caret)
library(doMC)
train <- read.csv("Data/train.csv",header=F)
names(train)
names(train)[-1]
names(train)[-1] <- paste0("V",1:40)
test <- read.csv("Data/test.csv",header=F)
rbind(train[,-1],test)
train <- read.csv("Data/train.csv",header=F)
y <- read.csv("Data/trainLabels.csv", header= F)
names(train) <- paste0("V",1:40)
rbind(train[,-1],test)
train <- read.csv("Data/train.csv",header=F)
y <- read.csv("Data/trainLabels.csv", header= F)
names(train) <- paste0("V",1:40)
test <- read.csv("Data/test.csv",header=F)
pca <- prcomp(rbind(train,test))
pca
pca$x[1:1000,])
pca$x[1:1000,]
pca$x[1:5,]
summary(pca)
train <- as.data.frame(cbind(train[,1],pca$x[1:1000,]))
head(train)
train <- as.data.frame(cbind(y[,1],pca$x[1:1000,]))
head(train)
train[,1] <- as.factor(ifelse(train[,1] == 0, "zero", "one"))
head(train)
names(train)[1] <- "label"
test <- as.data.frame(pca$x[1001:10000,])
registerDoMC(10)
rfeFuncs <- rfFuncs
?doMC
rfeFuncs
?rfFuncs
rfeFuncs$summary
rfeFuncs$summary <- twoClassSummary
rfeFuncs$summary
rfe.control <- rfeControl(rfeFuncs, method = "repeatedcv", number=10 ,repeats = 4, verbose = FALSE, returnResamp = "final")
?rfe
rfe.rf <- rfe(train, y, sizes = 10:15, rfeControl = rfe.control,metric="ROC")
dim(x)
dim(y)
rfe.rf <- rfe(train[,-1], train[,1], sizes = 10:15, rfeControl = rfe.control,metric="ROC")
rfe.rf
train <- train[,c("label",predictors(rfe.rf))]
test <- test[,predictors(rfe.rf)]
save(train,test,file="Data/trainData.RData")
test
registerDoMC(7)
pp <- c("center","scale")
sumFunc <- function (data, lev = NULL, model = NULL) {
require(pROC)
if (!all(levels(data[, "pred"]) == levels(data[, "obs"])))
stop("levels of observed and predicted data do not match")
rocObject <- try(pROC:::roc(data$obs, data[, lev[1]]), silent = TRUE)
rocAUC <- if (class(rocObject)[1] == "try-error")
NA
else rocObject$auc
out <- c(mean(data[,"pred"]==data[,"obs"]),rocAUC, sensitivity(data[, "pred"], data[, "obs"], lev[1]), specificity(data[, "pred"], data[, "obs"], lev[2]))
names(out) <- c("ACC","ROC", "Sens", "Spec")
out
}
require(pROC)
tc <- trainControl(method="repeatedcv",number=10,repeats=4,classProbs=T,savePred=T,index=createMultiFolds(train$label, k=10, times=5),summaryFunction=sumFunc)
(model <- train(label~.,data=train,method="avNNet",trControl=tc,preProcess=pp,metric="ROC",tuneGrid=expand.grid(.bag=c(F),.size=c(27:28),.decay=c(0.17)),allowParallel=F))
test.pred <- predict(model,test,type="prob")[,"one"]
head(test.pred)
newtraini <- which(test.pred >= 0.98 | test.pred <= 0.02)
newtraini
newtrain <- test[newtraini,]
newtrain$label <- as.factor(ifelse(test.pred[newtraini] < 0.5, "zero","one"))
train <- rbind(train,newtrain[,names(train)])
head(train)
tc$index <- lapply(tc$index,function(fold) c(fold,1001:nrow(train)))
tc$index
(model.semi <- train(label~.,data=train,method="avNNet",trControl=tc,preProcess=pp,metric="ROC",tuneGrid=expand.grid(.bag=c(F),.size=c(27:28),.decay=c(0.17)),allowParallel=F))
test.pred.semi <- predict(model.semi,test,type="prob")[,"one"]
test.pred <- (test.pred+test.pred.semi)/2
write.csv(data.frame(id=1:length(test.pred),solution=ifelse(test.pred < 0.5, 0 ,1)),file="Data/submission_25Sep2014.csv",row.names=F)
rm(list=ls())
load("Data/trainData.RData")
registerDoMC(7)
pp <- c("center","scale")
sumFunc <- function (data, lev = NULL, model = NULL) {
require(pROC)
if (!all(levels(data[, "pred"]) == levels(data[, "obs"])))
stop("levels of observed and predicted data do not match")
rocObject <- try(pROC:::roc(data$obs, data[, lev[1]]), silent = TRUE)
rocAUC <- if (class(rocObject)[1] == "try-error")
NA
else rocObject$auc
out <- c(mean(data[,"pred"]==data[,"obs"]),rocAUC, sensitivity(data[, "pred"], data[, "obs"], lev[1]), specificity(data[, "pred"], data[, "obs"], lev[2]))
names(out) <- c("ACC","ROC", "Sens", "Spec")
out
}
tc <- trainControl(method="repeatedcv",number=10,repeats=10,classProbs=T,savePred=T,index=createMultiFolds(train$label, k=10, times=5),summaryFunction=sumFunc)
(model <- train(label~.,data=train,method="avNNet",trControl=tc,preProcess=pp,metric="ROC",tuneGrid=expand.grid(.bag=c(F),.size=c(27:28),.decay=c(0.17)),allowParallel=F))
test.pred <- predict(model,test,type="prob")[,"one"]
##################################
## Semisupervised Self Training ##
##################################
#add cases
newtraini <- which(test.pred >= 0.98 | test.pred <= 0.02)
newtrain <- test[newtraini,]
newtrain$label <- as.factor(ifelse(test.pred[newtraini] < 0.5, "zero","one"))
train <- rbind(train,newtrain[,names(train)])
#make new model
tc$index <- lapply(tc$index,function(fold) c(fold,1001:nrow(train)))
(model.semi <- train(label~.,data=train,method="avNNet",trControl=tc,preProcess=pp,metric="ROC",tuneGrid=expand.grid(.bag=c(F),.size=c(27:28),.decay=c(0.17)),allowParallel=F))
test.pred.semi <- predict(model.semi,test,type="prob")[,"one"]
test.pred <- (test.pred+test.pred.semi)/2
write.csv(data.frame(id=1:length(test.pred),solution=ifelse(test.pred < 0.5, 0 ,1)),file="Data/submission_25Sep2014_pm.csv",row.names=F)
rm(list=ls())
train <- read.csv("Data/train.csv",header=F)
y <- read.csv("Data/trainLabels.csv", header= F)
names(train) <- paste0("V",1:40)
test <- read.csv("Data/test.csv",header=F)
head(test)
head(train)
head(y)
pca <- prcomp(rbind(train,test))
train <- as.data.frame(cbind(y,pca$x[1:1000,]))
head(train)
train[,1] <- as.factor(ifelse(train[,1] == 0, "zero", "one"))
names(train)[1] <- "label"
test <- as.data.frame(pca$x[1001:10000,])
?rfFuncs
?twoClassSummary
registerDoMC(10)
rfeFuncs <- rfFuncs
rfeFuncs$summary <- twoClassSummary
?rfeControl
rfe.control <- rfeControl(rfeFuncs, method = "repeatedcv", number=10 ,repeats = 10, verbose = T, returnResamp = "final")
rfe.control
?rfe
head(train[,-1])
rfe.rf <- rfe(train[,-1], train[,1], sizes = 10:25, rfeControl = rfe.control,metric="ROC")
train <- train[,c("label",predictors(rfe.rf))]
test <- test[,predictors(rfe.rf)]
save(train,test,file="Data/trainData2.RData")
##################
## Build Models ##
##################
load("Data/trainData2.RData")
registerDoMC(7)
pp <- c("center","scale")
sumFunc <- function (data, lev = NULL, model = NULL) {
require(pROC)
if (!all(levels(data[, "pred"]) == levels(data[, "obs"])))
stop("levels of observed and predicted data do not match")
rocObject <- try(pROC:::roc(data$obs, data[, lev[1]]), silent = TRUE)
rocAUC <- if (class(rocObject)[1] == "try-error")
NA
else rocObject$auc
out <- c(mean(data[,"pred"]==data[,"obs"]),rocAUC, sensitivity(data[, "pred"], data[, "obs"], lev[1]), specificity(data[, "pred"], data[, "obs"], lev[2]))
names(out) <- c("ACC","ROC", "Sens", "Spec")
out
}
levels(train[, "pred"]
)
levels(train[, "pred"])
?all
tc <- trainControl(method="repeatedcv",number=10,repeats=10,classProbs=T,savePred=T,index=createMultiFolds(train$label, k=10, times=5),summaryFunction=sumFunc)
?createMultiFolds
?trainControl
?avNNet
tc <- trainControl(method="repeatedcv",number=10,repeats=10,classProbs=T,savePred=T,index=createMultiFolds(train$label, k=10, times=5),summaryFunction=sumFunc)
?trainControl
(model <- train(label~.,data=train,method="avNNet",trControl=tc,preProcess=pp,metric="ROC",tuneGrid=expand.grid(.bag=c(F),.size=c(27:28),.decay=c(0.17)),allowParallel=F))
(model <- train(label~.,data=train,method="avNNet",trControl=tc,preProcess=pp,metric="ROC",tuneGrid=expand.grid(.bag=c(T),.size=c(25:30),.decay=c(0.17)),allowParallel=F))
test.pred <- predict(model,test,type="prob")[,"one"]
head(test.pred)
predict(model,test,type="prob")
head(predict(model,test,type="prob"))
newtraini <- which(test.pred >= 0.98 | test.pred <= 0.02)
head(which(test.pred >= 0.98 | test.pred <= 0.02))
newtraini
newtrain <- test[newtraini,]
newtrain$label <- as.factor(ifelse(test.pred[newtraini] < 0.5, "zero","one"))
head(newtrain)
train <- rbind(train,newtrain[,names(train)])
tc$index
tc$index <- lapply(tc$index,function(fold) c(fold,1001:nrow(train)))
tc$index <- lapply(tc$index,function(fold) c(fold,1001:nrow(train)))
model
(model.semi <- train(label~.,data=train,method="avNNet",trControl=tc,preProcess=pp,metric="ROC",tuneGrid=expand.grid(.bag=c(T),.size=c(20:35),.decay=c(0.17)),allowParallel=F))
test.pred.semi <- predict(model.semi,test,type="prob")[,"one"]
test.pred <- (test.pred+test.pred.semi)/2
write.csv(data.frame(id=1:length(test.pred),solution=ifelse(test.pred < 0.5, 0 ,1)),file="Data/submission_25Sep2014_5pm.csv",row.names=F)
